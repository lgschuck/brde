[
  {
    "objectID": "analise_dados.html",
    "href": "analise_dados.html",
    "title": "Análise de Dados e Informações",
    "section": "",
    "text": "c) Análise de dados e informações: Dado, informação, conhecimento e inteligência; Conceitos, fundamentos, características, técnicas e métodos de Business Intelligence (BI); Mapeamento de fontes de dados, Dados estruturados e dados não estruturados, Conceitos de OLAP e suas operações, Conceitos de Data Warehouse. Técnicas de modelagem e otimização de bases de dados multidimensionais, Construção de relatórios e dashboards interativos em ferramentas de BI, Manipulação de dados em planilhas, Geração de insights a partir de relatórios e dashboards, BI como suporte a processos de tomada decisão, Conceitos Básicos em Séries Temporais, Conceitos Básicos de estatística descritiva, probabilística e testes de hipótese, Manipulação, tratamento e visualização de dados, Tratamento de dados faltantes, Tratamento de dados categóricos, Normalização numérica, Detecção e tratamento de outliers"
  },
  {
    "objectID": "banco_dados.html",
    "href": "banco_dados.html",
    "title": "Banco de Dados",
    "section": "",
    "text": "a) Banco de Dados: Fundamentos de administração de dados: Segurança; Modelagem de dados: Modelo entidade-relacionamento (entidades, atributos, chaves e relacionamentos) e Normalização;"
  },
  {
    "objectID": "conceitos_bi.html",
    "href": "conceitos_bi.html",
    "title": "Conceitos de BI",
    "section": "",
    "text": "Conceitos, fundamentos, características, técnicas e métodos de Business Intelligence (BI)"
  },
  {
    "objectID": "conceitos_bi.html#brasil-escola",
    "href": "conceitos_bi.html#brasil-escola",
    "title": "Conceitos de BI",
    "section": "Brasil Escola",
    "text": "Brasil Escola"
  },
  {
    "objectID": "conceitos_bi.html#business-intelligence",
    "href": "conceitos_bi.html#business-intelligence",
    "title": "Conceitos de BI",
    "section": "4. BUSINESS INTELLIGENCE",
    "text": "4. BUSINESS INTELLIGENCE\nO conceito de business Intelligence foi nomeado pelo Gartner Group, grupo com enfoque no uso de tecnologias para a tomada de decisão, nos anos 1990, porém, sua ideia base vem de muito antes. Quando se tem uma coleta de informações para a tomada de decisão, isso, a grosso modo, é business Intelligence. Mas a partir da nossa evolução no mundo tecnológico, o BI, vem sendo auxiliado e por inúmeras ferramentas, como o Sistemas de Informações Executivas/EIS, que começou a ser utilizado nos anos 1980, fornecendo informações a nível estratégicos das organizações, como relatórios dinâmicos e análise de tendências, sistema esse que mais tarde, juntamente com todas as suas ferramentas, seria chamado de soluções em BI.\nEm meados dos anos 1980, começou a surgir às primeiras soluções baseadas em gerenciamento de banco de dados com modelo relacional, isso implica que as informações geradas eram dispostas em tabelas com suas respectivas descrições, mesmo hoje é o modelo mais utilizado quando se diz respeito a banco de dados. Com essas novas ferramentas, se tornou mais viável o uso do sistema de informação Enterprise Resource Planning/ERP, que é a integração de todos os dados gerados pela organização.\nSegundo Davenport (1998), o ERP é definido como:\nUm software de negócio que permite à empresa automatizar e integrar a maioria de seus processos; compartilhar práticas de negócio e dados comuns pela empresa; e disponibilizar a informação em tempo real”.\nÉ visto como a solução para acabar com os vários programas que funcionam no mesmo ambiente empresarial, sem integração, produzindo informações de pouca qualidade para o negócio. Sistemas dessa natureza são adquiridos com o intuito de tornar os processos empresariais mais ágeis e extrair informações mais acuradas da empresa.\nMesmo sendo uma enorme vantagem o uso de softwares de ERP, o processo de análise de informações ainda era complicado, pois se utiliza um modelo relacional que, dependendo da sua arquitetura, não pode ser usado para a análise consistente de resultados. Os ERP são disponibilizados a partir de módulos, que se adaptam as necessidades das empresas, partindo disso e do problema em análise de dados, as empresas de ERP, passaram a incluir módulos específicos em BI.\nComo é citado pelo brasileiro Carlos Barbieri (2001, XX):\nNo fundo, tudo relativo à nova era da economia da informação, dedicada à captura de dados, informações e conhecimentos que permitam às empresas competirem com maior eficiência num ring de disputas leoninas”.\nConsiderando a utilização dos ERP, e as suas estruturas de dados, ficou nítido a necessidade de um armazenamento de dados especifico para se gerar informações confiáveis, então, começou a se pensar na utilização de um armazenamento de dados, que foi introduzido inicialmente na década de 1960 pela International Business Machines/IBM, empresa americana voltada para a área de informática, modelo chamado de Data Warehouse/DW (inicialmente o modelo era chamado de Information Warehouse).\nO Data Warehouse, segundo DALFOVO e TAMBORLIN (2006),\n[...] pode ser definido como um banco de dados especializado, que integra e gerencia o fluxo de informações a partir dos bancos de dados corporativos e fontes de dados externas à empresa, [...]“.\nNeste Sentido, o DW serve para criar uma visão centralizada e única dos dados que foram gerados em diversos outros bancos de dados. É a partir daí que o BI gera relatórios e informações, porém, ao contrário do ERP, podem ser utilizados por muitas outras pessoas na organização.\nMas afinal, qual o conceito de BI?\nO BI não pode ser enquadrado como um sistema, nem como um produto e nem as suas ferramentas, mas pode ser compreendido como o uso de arquiteturas, aplicativos e banco de dados (ZAMAN, 2005)\nDe acordo com Carlos Barbieri (2001, p.34), BI pode ser definido como “a utilização de variadas fontes de informação para se definir estratégias de competitividade nos negócios da empresa”, várias fontes de informações, pois como o acesso à tecnologia se tornou mais viável à população, mais informações de diferentes fontes, como mídias sociais, telefone e e-mail, são geradas. Informações essas que em sua maioria não podem ser analisadas, pois não foram “higienizadas”, ou estão em várias tabelas, onde se torna inviável a relação com outras tabelas, para gerar o que de fato é importante."
  },
  {
    "objectID": "conceitos_bi.html#etapas-técnicas-e-características-de-bi",
    "href": "conceitos_bi.html#etapas-técnicas-e-características-de-bi",
    "title": "Conceitos de BI",
    "section": "5. ETAPAS, TÉCNICAS E CARACTERÍSTICAS DE BI",
    "text": "5. ETAPAS, TÉCNICAS E CARACTERÍSTICAS DE BI\nO BI, como em qualquer projeto a ser implementando possuem suas etapas, que nem sempre precisam ser seguidas a riscas, mas facilitam no processo, pois assim, um modelo de projeto possa ser utilizado por outras organizações ou em implementações futuras.\nComumente, uma implementação de um projeto BI não se difere de outros projetos, no que diz respeito na forma como são levantadas as necessidades, porém, possuem suas particularidades. Abaixo, encontra-se um modelo para o desenvolvimento que pode ser a base para qualquer projeto.\n\nDefinição de requisitos\n\nPrimeira etapa, onde se deve entender a forma como o desenvolvimento vai acontecer e o resultado a ser alcançado.\n\nEstrutura do Data Warehouse\n\nDesenhar a estrutura necessária para o DW (ver seção 4.1), assim como a centralização das informações que são pertinentes, é onde também, se necessário, estruturar o Data Mart (ver seção 4.1.4).\n\nDefinição do ETL\n\nApós estruturar o DW, é necessário vincular a fonte de dados original, esse processo pode ser demorado então é de suma importância que sua implementação seja bastante consolidada (ver seção 4.1.6).\n\nEstrutura do cubo OLAP\n\nApós a estrutura do DW pronta, o ETL carregando essas informações, é necessário a criação de um cubo OLAP, que tem como finalidade agilizar a criação de relatórios, os detalhes estão na seção 4.2.\n\nDashboards\n\nApós o projeto finalizado, irão ser utilizados softwares que serão conectados ao Cubo OLAP e que possuem a característica de gerar Dashboards, ou gráficos para a análise e tomada de decisão na organização."
  },
  {
    "objectID": "dado_info.html",
    "href": "dado_info.html",
    "title": "Dado, informação, conhecimento e Inteligência",
    "section": "",
    "text": "c) Análise de dados e informações: Dado, informação, conhecimento e inteligência;\nDado\nDesde que entramos na ERA da INFORMAÇÃO, o dado é um elemento de suma importância. Nas atividades diárias necessitamos de aplicações que envolvem bancos de dados. Exemplos: aplicações de Internet Banking; reservas em hotéis ou companhias aéreas; etc.\nMas, o que é um dado? É um registro de alguma entidade. Um nome é um dado, uma foto é um dado, 134 é um dado, 5 é um dado, etc. Trata-se de uma sequência de símbolos, também conhecidos como signos, que podem ser representados com sons, imagens, textos, números e estruturas. Não há semântica envolvida no dado. Não há uma interpretação sobre essa sequência de símbolos. É algo “bruto”, como o número 10 ou a letra F.\nMoresi (2001) destaca que dados são fatos ou observações “crus”. Mais especificamente, os dados são medidas objetivas e quantitativas dos atributos (características) de entidades como pessoas, lugares, coisas e eventos (conjunto de fatos).\nOs dados são uma parte pequena da informação, que sozinhos não fazem sentido!\nInformação\nJá a informação é um dado depois de processado, é uma contextualização de um dado… Como assim? “5” é um dado, mas e se eu disser o seguinte: “No dia 5 não haverá aula!”. Nesse caso, o 5 passou a ter sentido (ou passou a ter “contexto”) e agora é uma informação!\nInformações são conjuntos de dados significativos e úteis a seres humanos em processos como o de tomada de decisões. “São dados interpretados, dotados de relevância e propósito” (DRUCKER, 1999).\nConforme destacado por Moresi (2001), informações são dados que foram organizados e ordenados de forma coerente e significativa para fins de compreensão e análise (sendo a base para ações coordenadas).\nA transformação de dados em informação é frequentemente realizada através da apresentação dos dados em uma forma compreensível ao usuário. As informações são produzidas pelo processamento de dados. Elas são utilizadas para revelar o significado dos dados.\n\nNa figura anterior, dados brutos registrados por um caixa de supermercados podem ser processados e organizados de modo a produzir informações úteis, tal como o total de unidades de detergentes vendidas ou a receita total de vendas do detergente para determinada loja ou território de vendas.\nConhecimento\nConhecimento (ou Capital Intelectual) é a habilidade de transformar a informação em ações reais. O conhecimento é uma mistura de elementos estruturados de forma intuitiva e, portanto, é difícil de ser colocado em palavras ou de ser plenamente entendido em termos lógicos.\nConhecimento, de acordo com Moresi (2001) é uma mistura fluída de experiências, informação contextual, valores e intuição, formando um painel na mente de uma pessoa que a habilita a avaliar e obter novas experiências e informações. O conhecimento é a consequência mental de angariar informações e, em sua forma mais desenvolvida, apresenta‑se como a capacidade de chegar a novas descobertas com base no aprendizado e na experiência. São informações que foram analisadas e avaliadas sobre a sua confiabilidade, sua relevância e sua importância.\nPara guardar uma informação, precisamos retê-la em nossa memória; para guardar um conhecimento, devemos incorporá-lo em nossa mente e, consequentemente, em nossa maneira de pensar.\nConhecimento demanda análise e avaliação sobre a confiabilidade, relevância e importância de dados e informações para a construção de um quadro de situação (Banca FCC/2015).\n\nInteligência\nA inteligência é o dom humano capaz de “digerir” as informações, por meio da análise, e transformá-la em conhecimento útil. Pode ser vista como o conhecimento que foi sintetizado e aplicadoa determinada situação para ganhar maior profundidade e consciência.\nBaseia-se na experiência e intuição e, portanto, é habilidade puramente humana. É a faculdade humana de conhecer, compreender, raciocinar, pensar e interpretar. Envolve exercício de ponderação para a tomada da melhor decisão, bem como noções de ética, bom e ruim, certo e errado.\nInteligência é a informação devidamente filtrada, destilada e analisada que pode apoiar a tomada de decisões. A transformação de conhecimento em inteligência ocorre por meio de síntese da experiência e, muito além do que qualquer sistema de análise de informação, necessita de habilidades humanas (MORESI, 2001).\nVamos esquematizar para facilitar a memorização desse assunto!\n\n\nFontes:\nPonto dos Concursos"
  },
  {
    "objectID": "datawarehouse.html",
    "href": "datawarehouse.html",
    "title": "Conceitos de Data Warehouse",
    "section": "",
    "text": "Conceitos de Data Warehouse"
  },
  {
    "objectID": "datawarehouse.html#aws",
    "href": "datawarehouse.html#aws",
    "title": "Conceitos de Data Warehouse",
    "section": "AWS",
    "text": "AWS\n\nO que é um data warehouse?\nUm data warehouse é um repositório central de informações que podem ser analisadas para tomar decisões mais adequadas. Os dados fluem de sistemas transacionais, bancos de dados relacionais e de outras fontes para o data warehouse, normalmente com uma cadência regular. Analistas de negócios, engenheiros de dados, cientistas de dados e tomadores de decisões acessam os dados por meio de ferramentas de inteligência de negócios (BI), clientes SQL e outros aplicativos de análise.\nDados e análises se tornaram indispensáveis para que as empresas se mantenham competitivas. Os usuários corporativos contam com relatórios, painéis e análises para extrair insights dos dados, monitorar a performance dos negócios e apoiar a tomada de decisões. Os data warehouses alimentam esses relatórios, painéis e ferramentas de análise armazenando dados de maneira eficiente para minimizar a entrada e saída (E/S) dos dados e fornecer resultados de consulta rapidamente para centenas e milhares de usuários simultaneamente.\n\n\nComo um data warehouse é arquitetado?\nUma arquitetura de data warehouses é composta de camadas. A camada superior é o cliente de front-end, que apresenta os resultados por meio de ferramentas de relatórios, análises e mineração de dados. A camada intermediária consiste no mecanismo de análises, usado para acessar e analisar os dados. A camada inferior da arquitetura é o servidor de banco de dados, onde os dados são carregados e armazenados. Os dados são armazenados de dois modos diferentes: 1) os dados acessados com frequência são armazenados em armazenamento muito rápido (como unidades SSD) e 2) os dados acessados com pouca frequência são armazenados em um armazenamento de objetos barato, como o Amazon S3. O data warehouse garantirá automaticamente que os dados acessados com frequência sejam movidos para o armazenamento “rápido”, para otimizar a velocidade da consulta.\n\n\n\nComo funciona um data warehouse?\nUm data warehouse pode conter vários bancos de dados. Dentro de cada banco de dados, os dados são organizados em tabelas e colunas. Dentro de cada coluna, você pode definir uma descrição dos dados, como número inteiro, campo de dados ou sequência. As tabelas podem ser organizadas dentro de esquemas, que você pode considerar como pastas. Quando os dados são consumidos, eles são armazenados em várias tabelas descritas pelo esquema. As ferramentas de consulta usam o esquema para determinar as tabelas de dados que serão acessadas e analisadas.\n\n\n\nQuais são os benefícios de usar um data warehouse?\nOs benefícios de um data warehouse incluem o seguinte:\n\nTomada de decisão adequada\nDados consolidados de várias fontes\nAnálise de dados históricos\nQualidade, consistência e precisão de dados\nSeparação do processamento analítico dos bancos de dados transacionais, o que melhora o desempenho dos dois sistemas\n\n\n\nComo os data warehouses, os bancos de dados e data lakes funcionam juntos?\nNormalmente, as empresas usam uma combinação de banco de dados, data lake e data warehouse para armazenar e analisar dados. A arquitetura de lake house do Amazon Redshift facilita essa integração.\nÀ medida que o volume e a variedade de dados aumentam, é vantajoso seguir um ou mais padrões comuns para trabalhar com dados em seu banco de dados, data lake e data warehouse:\n\n\nImagem (acima): armazenar os dados em um banco de dados ou datalake, preparar os dados, mover os dados selecionados para um data warehouse e executar relatórios.\n\nImage (acima): armazenar os dados em uma data warehouse, analisar os dados e compartilhá-los para usar com outros serviços de análise e machine learning.\nUm data warehouse é projetado especificamente para análises de dados, que envolvem a leitura de grandes quantidades de dados para compreender relações e tendências entre os dados. Um banco de dados é usado para capturar e armazenar dados, como o registro de detalhes de uma transação.\nAo contrário de um data warehouse, um data lake é um repositório centralizado para todos os dados, incluindo estruturados, semiestruturados e não estruturados. Um data warehouse exige que os dados sejam organizados em um formato tabular, onde o esquema torna-se necessário. O formato tabular é necessário para que o SQL possa ser usado para consultar os dados, mas nem todos os aplicativos exigem que os dados estejam em formato de tabela. Alguns aplicativos, como análise de big data, pesquisa de texto completo e machine learning, podem acessar dados mesmo que sejam “semiestruturados” ou completamente não estruturados.\n\n\n\nComparação entre data warehouses e data lakes\n\n\n\n\n\n\n\n\nCaracterísticas\nData warehouse\nData lake\n\n\n\n\nDados\nDados relacionais de sistemas transacionais, bancos de dados operacionais e aplicativos de linha de negócios\nTodos os dados, incluindo estruturados, semiestruturados e não estruturados\n\n\nEsquema\nGeralmente projetado antes da implementação do data warehouse, mas também pode ser gravado no momento da análise\n(esquema na gravação ou esquema na leitura)\nGravado no momento da análise (esquema na leitura)\n\n\nPreço/performance\nResultados de consulta mais rápidos, usando armazenamento local\nResultados da consulta cada vez mais rápidos usando armazenamento de baixo custo e desacoplamento de computação e armazenamento\n\n\nQualidade dos dados\nDados altamente organizados, que representam a versão central da verdade\nQuaisquer dados, organizados ou não (ou seja, dados brutos)\n\n\nUsuários\nAnalistas de negócios, cientistas de dados e desenvolvedores de dados\nAnalistas de negócios (usando dados organizados), cientistas de dados, desenvolvedores de dados, engenheiros de dados e arquitetos de dados\n\n\nAnálises\nGeração de relatórios em lote, BI e visualizações\nMachine learning, análise exploratória, descoberta de dados, streaming, análise operacional, big data e criação de perfil\n\n\n\n\n\nComparação entre data warehouses e bancos de dados\n\n\n\n\n\n\n\n\nCaracterísticas\nData warehouse\nBanco de dados transacional\n\n\n\n\nCargas de trabalho adequadas\nAnálises, relatórios e big data\nProcessamento de transações\n\n\nFonte de dados\nDados coletados e normalizados de diversas fontes\nDados capturados no estado em que se encontram, de uma única fonte, como um sistema transacional\n\n\nCaptura de dados\nOperações de gravação em massa, executadas normalmente em uma programação de lotes pré-determinada\nOtimizado para operações contínuas de gravação à medida que novos dados são disponibilizados para maximizar o throughput das transações\n\n\nNormalização de dados\nEsquemas desnormalizados, como Star ou Snowflake\nEsquemas estáticos altamente normalizados\n\n\nArmazenamento de dados\nOtimizado para simplicidade de acesso e alto desempenho de consultas usando armazenamento colunar\nOtimizado para operações de gravação de alto throughput em um único bloco físico orientado a linhas\n\n\nAcesso aos dados\nOtimizado para minimizar a E/S e maximizar o throughput de dados\nGrandes volumes de pequenas operações de leitura\n\n\n\n\n\nComo um data mart se compara a um data warehouse?\nUm data mart é um data warehouse que atende às necessidades de uma equipe ou unidade de negócios específica, como finanças, marketing ou vendas. O data mart é menor, mais focado e pode conter resumos de dados para atender melhor à comunidade de usuários. Um data mart também pode ser uma parte de um data warehouse.\n\n\n\nComparação entre data warehouses e data marts\n\n\n\nCaracterísticas\nData warehouse\nData mart\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaracterísticas\nData warehouse\nData mart\n\n\n\n\nEscopo\nVárias áreas centralizadas e integradas\nUma área específica e descentralizada\n\n\nUsuários\nDe toda a organização\nUma única comunidade ou departamento\n\n\nFonte de dados\nMuitas fontes\nUma ou poucas fontes, ou uma parte dos dados já coletados em um data warehouse\n\n\nTamanho\nGrande, pode variar de centenas de gigabytes a petabytes\nPequeno, normalmente até algumas dezenas de gigabytes\n\n\nProjeto\nDe cima para baixo\nDe baixo para cima\n\n\nDetalhes dos dados\nDados completos e detalhados\nPode manter dados resumidos"
  },
  {
    "objectID": "datawarehouse.html#brasil-escola",
    "href": "datawarehouse.html#brasil-escola",
    "title": "Conceitos de Data Warehouse",
    "section": "Brasil Escola",
    "text": "Brasil Escola\n\n5.1. DATA WAREHOUSE\nO conceito de Data Warehouse surgiu da necessidade das organizações em integrar os dados de diferentes servidores e máquinas em apenas um local e que essas informações servissem para que fossem gerados relatórios para as análises da empresa. O DW usa um modelo relacional dimensional, isto é, as informações estão dispostas de formas intuitivas, facilitando o acesso e a geração de resultados.\nOutro fator determinante para o desenvolvimento de um armazém de dados é o fato de que os modelos tradicionais, gerados pelos sistemas ERP, estão estruturados de forma transacional, o que dificulta gerar informações para as análises de resultados. De acordo com Singh, 2001: “O DW é a área de armazenamento de dados históricos e integrados destinados a sistemas de suporte à decisão”.\nAssim, Barbieri, 2001, conclui que:\nPode ser definido como um banco de dados, destinado a sistemas de apoio à tomada de decisão e cujos dados foram armazenados em estruturas lógicas dimensionais, possibilitando o seu processamento analítico por ferramentas especiais”.\nAs decisões para a utilização de um DW, parte do princípio que as informações precisam ser confiáveis para que as decisões não sejam tomadas de forma errônea. Como afirma Kimball, 2002: “Queremos que as pessoas usem informações para apoiar decisões mais baseadas em fatos”. As consultas e relatórios são acessados diretamente no DW, evitando dados sem confiabilidade dos provedores de informações originais.\n\n5.1.1. Características\n\n\n5.1.2. Orientado por Assunto\nOs bancos de dados transacionais, comumente possuem todos os dados das organizações dispostas em tabelas, isso faz com que os dados nem sempre serão de fácil análise. Os DW, por sua vez são orientados aos assuntos mais pertinentes para as empresas, como a análise de mercado de determinado produto ou veículo. Na figura 1, nota-se a diferença entre sistemas operacionais comum e após a criação do DW.\nFigura 1: Orientada por assunto\n\nFonte: INMON, 2005.\nBarbieri, 2001, nos alerta que a falta e objetivo, são primordiais para o fracasso de qualquer projeto, mas isso ainda é mais agravante no que diz respeito ao DW. É preciso também pensar no futuro, se necessário uma expansão no mesmo isso deve acontecer de forma relativamente fácil, pois se o projeto for mal estrutura, pode ser que o projeto futuramente tenha que partir do zero.\n\n\n5.1.3. Integrado\nÉ comum as organizações possuírem mais de uma representante, ou filial, sendo para desenvolver as mesmas ações ou de diferente tipo, fazendo com que em certos momentos as informações serão escritas de formas diferentes a qual está na matriz, ou representante principal. Ou então o sistema ERP é diferente, isso gera inconsistência nos dados, já que as informações são provenientes de mais de uma fonte.\nUma das características mais importantes do DW é a capacidade de ler essas informações e armazená-las de forma confiável. Independe de onde vem as informações, ou da data em que foi criado, a integração no DW sempre será consistente, por exemplo. Na inserção do CPF de clientes de um grupo de empresas, na organização X o CPF é inserido da seguinte forma: 999.999.999-99 já na empresa Y insere assim: 99999999999, a princípio pode ser uma questão simples, mas no momento em que for cruzar as informações, não será possível “linkar” um CPF com o outro. O DW irá transformar essas informações num modelo único.\n\n\n5.1.4. Histórico\nO que influência o tamanho do DW é principalmente as informações históricas das organizações, a forma mais eficaz de análise de tendência é tendo informações de anos anteriores para a comparação. Os dados históricos dos DW podem ter facilmente mais de 5 anos. Nos sistemas tradicionais, as informações remetem a posição atual dos dados no momento da pesquisa, ou num curto período de tempo, não sendo possível uma análise mais a fundo. É comum nos sistemas tradicionais a remoção de dados antigos para a liberação de espaço no banco de dados, isso não ocorre no DW pois as informações sempre serão importantes para as análises e projeção do futuro.\n\n\n5.1.5. Não Volátil\nHá apenas duas operações executadas no DW, a primeira delas é a transação de carga dos dados provenientes dos sistemas provedores de informações e a segunda é o processo de leitura dos dados para a geração de relatórios. Não é possível a escrita de dados nas dimensões do DW diretamente como acontece nos bancos de dados tradicionais, sendo apenas para a leitura, fazendo com que as informações permaneçam estáveis mesmo após longos períodos de tempo.\n\n\n5.1.6. Modelos\nTodas as características do DW, bem como suas diferenças aos sistemas tradicionais passam inteiramente pelos modelos a serem usados para a construção do novo repositório de dados. Os modelos, a grosso modo é a forma como os dados serão organizados e estruturados, como as entidades serão conectadas e como irão interagir entre si.\nAs opções de estrutura no DW variam das necessidades de cada caso, as mais comuns atualmente são o Modelo Estrela (Star Schema) e o Modelo Floco de Neve (Snow Flake), cada um com sua característica e limitação referente ao outro.\n\n\n5.1.7. Modelo Estrela\nO modelo estrela foi proposto por Ralph Kimball, para ser um modelo altamente redundante, onde todas as descrições seriam repetidas em cada dimensão. Sua estrutura é composta por uma tabela central de Fatos e um conjunto de tabelas ligadas a ela, que são chamadas de dimensões. As dimensões são compostas por eventos ou características do mesmo, enquanto a tabela fato, como o próprio nome diz, armazena os fatos ocorridos, por exemplo, o Fato é a venda de um veículo, as dimensões são as informações dessa venda, como a data que ocorreu, veículo vendido, valor da venda e assim por diante. Na figura 2 pode se verificar a estrutura do modelo estrela.\nFigura 2: Modelo Estrela.\n\n Fonte: MACHADO, 2004.\nSegundo Singh (2001) uma característica importante desse modelo é fato de suas dimensões serem desnormalizadas, isto gera várias duplicidades no banco, mas também garante confiabilidade nas consultas. Barbieri, 2001, cita como desvantagem do modelo estrela o fato de ele não ter uma perfeita coesão entre os Data Marts e um esforço redobrado na extração de dados, já que várias informações são duplicadas.\n\n\n5.1.8. Modelo Floco de Neve\nO modelo floco de neve também possui uma tabela Fatos ligada as entidades de dimensões, porém, ao contrário do que ocorre com o modelo estrela, há entidades relacionando entre si, isto diminui drasticamente o tamanho do DW, porém as consultas podem se tornar um pouco complicadas. Na figura 3 observa-se a estrutura do modelo Floco de neve.\nFigura 3: Modelo Floco de neve\n\nFonte: MACHADO, 2004.\nSegundo Machado (2004), O modelo floco de neve é o resultado da decomposição de uma ou mais dimensões que possuem hierarquias entre seus membros. O que difere também do modelo estrela é o fato das dimensões serem normalizadas, não ocorrendo as duplicidades que ocorre no modelo estrela, SINGH (2001) completa dizendo que normalizando os dados das tabelas dimensionais de um modelo estrela transforma o mesmo em um modelo floco de neve.\n\n\n5.1.9. Estrutura Do Data Warehouse\nSegundo o Kimball group, grupo especializado na concepção de Data Warehouse para Business Intelligence, a estrutura base para um Data warehouse seria, composta por três componentes, Data Sources, Data Staging Area e Data Presentation Area. Na figura 4 observa-se a organização básica de um DW.\nFigura 4: DW\n\nFonte: kimballgroup, 2002\n\n\n5.1.10. Data Source\nSão De Onde As Informações Serão Extraídas, A Fonte Dos Dados, Independentemente do servidor que está em uso, por exemplo, uma organização possui duas fontes de dados, uma baseada em SGBD Oracle e a outra em SQL server, o DW tem por função integrar esses dados em apenas um local de forma que possam ser cruzadas informações.\n\n\n5.1.11. Data Staging\nÉ onde estão armazenados os dados, é um meio termo entre o sistema operacional e a camada de apresentação, fazendo uso de conjuntos de processos chamados de ETL (Extração, Transformação e carregamento), ver seção 4.1.6 É onde ocorre a “higienização” dos dados, onde são definidas as estruturas, os fatos e as dimensões do DW. O Data Staging, não é de acesso livre aos usuários, pois não gera relatórios e nem consultas, ficando a cargo do Data Presentation Area.\nKIMBALL (2002), indica o requisito do Data Staging:\nO requisito de arquitetura chave para a Data Staging é que ela esteja fora do alcance dos usuários de negócios, não fornecendo serviços de consulta e apresentação.”\nFigura 5: Staging area\n\nFonte: MACHADO, 2004.\n\n\n5.1.12. Data Presentation Area\nÉ onde os dados estão organizados e prontos para serem acessados pelos usuários. Com base num modelo dimensional, os dados são acessados de forma intuitiva e as informações são consistentes. As ferramentas que possuem essa finalidade são conectadas ao cubo OLAP (ver seção 4.2) e com auxílio das operações apresentam os relatórios para o usuário final.\n\n\n5.1.13. Data Mart\nTendo como base o exemplo citado referente a venda de um determinado veículo, é possível extrair as informações dessa venda, porém se necessário obter várias vendas, com vários filtros essas informações tendem a se tornarem complexas para se analisar e consequentemente para tomar decisões, em razão disso, a ideia de um diretório exclusivo a determinado assunto dentro do próprio DW, ou extraindo informações diretamente das fontes de dados, acabou se tornando bastante necessário.\nSegundo Silva (2003), há um consenso sobre Data marts:\n“Há um consenso entre os fornecedores de soluções de Data Warehouse. A idéia é começar pequeno, mas pensando grande. E é o que está acontecendo. Na maioria dos casos, as empresas que optam pelo Data Warehouse iniciam o processo a partir de uma área específica da empresa para depois ir crescendo aos poucos.”\nBarbieri (2001), nos elucida que, Data Mart é um depósito de dados que atende as áreas especificas da empresa, ou seja, separa por assuntos os dados coletados, Primak (2008) complementa dizendo que pode-se dividir um DW em vários Data Marts, com seus determinados assuntos e diminuindo o tempo de resposta e facilitando o acesso a essas informações, no cenário da venda de veículos, temos a tabela principal, que no caso é a “fatovendas” que tem todas as informações de vendas de determinado veículo, mas é possível também a criação de Data Marts específicos, como “fatorh”, que terá as informações do recursos humanos da organização, “fatofluxo”, responsável por catalogar o fluxo de clientes e assim por diante, mas ainda assim, possibilitando cruzar essas informações utilizando operações (ver seção 4.2.1), por exemplo, é possível emitir um dashboard das vendas pelo fluxo de clientes, podendo ter ideia de quantos clientes são necessários para finalizar uma venda, ou então traçar uma linha do tempo das vendas, pelo valor investido em marketing naquele período. Na figura 6, nota-se como se estrutura o Data Mart em um DW.\nFigura 6: Organização do Data Mart\n\nFonte: NERY, 2007.\n\n\n5.1.14. Data Mining\nA diferença básica do BI para o Data mining se refere a quem é direcionado a atuação. O BI tem como base fornecer as informações para o nível estratégico da organização, onde se tomam as decisões a níveis gerenciais, já o Data mining fornece as informações em níveis menores, são usadas principalmente na área de atuação, ou no plano tático da empresa.\nO DM é constituído por um conjunto de 3 conceitos básicos para o seu sucesso, são eles:\n\nEstatística\nInteligencia artificial\nMachine learning\n\nO Machine Learning nada mais é que a combinação dos dois primeiros conceitos, é a grosso modo o fato do DM “aprender com os dados”, com cálculos estatísticos e com uma boa inteligência artificial é possível que o software trace caminhos sozinhos para a obtenção de resultados.\n\n\n5.1.15. ETL – Extract, Transform And Load\nÉ o processo de extração dos dados de fontes externas para o Data Warehouse, transformando suas tabelas e informações em dimensões e fatos no DW e carregando todas as informações de forma “limpa” e consistente no banco em questão.\nFigura 7: ETL\n\nFONTE: CANALTECH, 2014.\nSegundo KIMBALL (1998), ETL é o Conjunto de processos pelos quais os dados de origem operacional são preparados para o Data Warehouse. KIMBALL (1998) completa, é o processo mais crítico e demorado na construção de um DW, podendo levar até 60% do total de horas da implementação do projeto. Pois os modelos relacionais, nem sempre dispõe de uma arquitetura que facilite isso, possuindo também o fator de quantidade de dados que o sistema possui.\nBarbieri, 2001, diz que o conceito do processo ETL, pode ser dividido em:\n\nFiltro de dados\n\nOs bancos de dados comuns não são normalizados, isto faz com que os dados possam ter informações indesejáveis, o papel do ETL nessa etapa é filtrar e não carregar no DW essas informações.\n\nIntegração de dados\n\nFazer com que todas as informações a determinado assunto sejam correlacionadas, independente se ela está num sistema no banco de dados, ou em planilhas locais.\n\nCondensação de dados\n\nÉ condensar as informações de forma sumariada, ou seja, as vendas de determinado dia, precisam sempre estar presentes juntamente com as outras vendas do mesmo dia.\n\nConversão de dados\n\nCada banco de dados apresentam as informações de formas distintas, podendo ser uma virgula ao invés de um ponto, ou até o símbolo de moeda ser diferente, o ETL converte esse modelo em um outro modelo padrão do DW.\n\nDerivação de dados\n\nContinuação da conversão de dados, mas atuando apenas nas informações, não em como o modelo é empregado.\nUma boa ferramenta de ETL deve ser capaz de se adaptar as mais formas de banco de dados, suas linguagens e seus formatos. Atualmente a oferta de ferramentas de ETL é bastante elevada, empresas que possuem ferramentas de BI, ou ferramentas para a construção de um DW normalmente disponibilizam um software especifico para a função, como é o caso SQL Server Integration Services e do Pentaho Data Integration, Ferramentas ETL dos softwares da Microsoft e da Pentaho, respectivamente."
  },
  {
    "objectID": "governanca_ti.html",
    "href": "governanca_ti.html",
    "title": "Governança de TI",
    "section": "",
    "text": "g) Governança de TI: ITIL versão 4 (ITIL 4): Operação de Serviços (Gerenciamento de Eventos, Gerenciamento de Incidentes, Gerenciamento de Problemas, Cumprimento de Requisições, Gerenciamento de Acessos), Desenho de Serviços (Gerenciamento de Níveis de Serviço, Gerenciamento de Capacidade, Gerenciamento de Disponibilidade, Gerenciamento de Continuidade de Serviços de TI, Gerenciamento de Continuidade de Negócio), Transição de Serviços (Gerenciamento de Configuração e Ativos de Serviços de TI, Gerenciamento de Liberação e Implantação, Gerenciamento de Mudanças), Melhoria Contínua de Serviços, Métricas (Fatores Críticos de Sucesso - CSFs, Índices Chave de Performance - KPIs)."
  },
  {
    "objectID": "governanca_ti.html#o-que-é-o-sistema-itil",
    "href": "governanca_ti.html#o-que-é-o-sistema-itil",
    "title": "Governança de TI",
    "section": "O que é o Sistema ITIL",
    "text": "O que é o Sistema ITIL\nO Sistema ITIL é um conjunto de boas práticas de gerenciamento de serviços de tecnologia de informação. Ele está de acordo com a norma ISO/IEC 20000, primeira padronização da International Organization for Standardization (ISO) voltada exclusivamente para a gestão de TI.\nITIL é a sigla para Information Technology Infrastructure Library – que pode ser traduzido para “biblioteca de infraestrutura de tecnologia da informação”.\nO sistema foi desenvolvido pela Agência Central de Computação e Telecomunicações (CCTA, na sigla em inglês) do Reino Unido na década de 1980, com o objetivo de estabelecer um padrão de segurança e confiabilidade na gestão de processos de TI, garantindo assim uma boa experiência para os usuários.\nPara isso, o modelo descreve boas práticas de infraestrutura, manutenção e operações. As orientações estão alinhadas aos métodos ágeis, ao DevOps e ao Lean, bastante utilizados por times de tecnologia.\nDesde que o ITIL foi proposto pela CCTA, o sistema passou por quatro grandes atualizações:\n\nITIL v1\nA primeira versão do ITIL era voltada para as agências governamentais, que começavam a se informatizar na década de 1980. Era, literalmente, uma biblioteca: uma coleção de livros físicos que chegou a mais de 30 volumes em 1996.\n\n\nITIL v2\nNos anos 2000 foi lançada a segunda versão do ITIL. Os 30 volumes foram condensados em 9, mas ainda eram voltados para entidades do governo britânico.\n\n\nITIL v3\nCom a popularização do modelo em empresas e demais entidades privadas, foi lançada uma nova atualização em maio de 2007.\nO ITIL v3 era descrito em 5 livros, que reuniam 26 processos e 4 funções. A maior inovação foi o conceito do Ciclo de Vida de Serviço (CVS), que era composto por dois componentes básicos:\n\nNúcleo do ITIL: conjunto de melhores práticas que podem ser adotadas por todas as organizações que prestam serviços ao negócio;\nGuias complementares do ITIL: boas práticas complementares reunidas em publicações específicas para diferentes setores da indústria, modelos operacionais e arquiteturas de TI.\n\nEm 2011, oITIL v3 ganhou uma grande atualização para dar clareza a conceitos e adicionar novas práticas ao CVS.\nÉ nesse período também que a CCTA foi incorporada ao Escritório de Comércio Governamental (OGC, na sigla em inglês), entidade do Reino Unido responsável por promover a eficiência nos processos de negócios do Estado.\nO sistema ITIL passou a ser atualizado pelo OGC até 2013, quando uma joint venture entre o governo britânico e a empresa Capita, a Axelos, assumiu o framework. Em 2021, a Axelos passou a fazer parte do grupo PeopleCert.\n\n\nITIL 4\nA quarta e última atualização do ITIL veio em fevereiro de 2019, com a publicação do livro “ITIL Foundations”.\nO modelo de gestão de TI foi alterado para atender as necessidades da Era Digital, com foco na criação de valor para os usuários, na condução de estratégias de negócios e na adaptação à transformação digital.\n\n\nAs principais mudanças do ITIL 4\nO ITIL 4 foi desenvolvido em conjunto entre a Axelos e a comunidade de profissionais de TI para adaptar o ITIL v3 às mudanças cada vez mais aceleradas da Era Digital.\nA principal mudança é a maior flexibilidade na execução dos processos. Na versão anterior, havia um certo engessamento no CVS, que dependia de uma série de estágios para ser executado.\nO ITIL 4 propõe o Sistema de Valor de Serviço (SVS) para alterar esse cenário. O SVS é um conjunto de componentes e atividades de uma empresa que possibilita a criação de valor.\nA flexibilidade vem da criação de um ecossistema entre organização, fornecedores, stakeholders e clientes. Todos devem atuar juntos para manter o sistema funcionando.\nOs componentes do SVS são:\n\nCadeia de valor de serviço: modelo operacional flexível para a entrega e aprimoramento contínuo de serviços. Tem como atividades principais planejar, melhorar, engajar, desenhar, construir e entregar;\n34 práticas que atualizam os processos do ITIL v3;\nGovernança: conjunto de normas e práticas que são a base para a definição de processos internos, de acordo com as exigências do setor e os valores da organização. Facilita a integração com outros frameworks como o COBIT.\nMelhoria contínua.\n\n\n\n\nRepresentação gráfica do Sistema de Valor de Serviços do ITIL 4.\n\n\nOutra mudança importante é a inclusão de tecnologias emergentes, como Cloud Computing, Infraestrutura como Serviço (IaaS), Machine Learning e blockchain.\nO ITIL 4 também introduziu novos conceitos, que você vai conhecer em detalhes a seguir.\n\n\nOs princípios do ITIL 4\nSão 7 princípios que devem orientar os profissionais de TI na adoção do SVS e, assim, adaptar o ITIL à realidade de suas empresas:\n\nConcentrar-se no valor;\nComeçar por onde você está;\nAvançar iterativamente com feedback;\nColaborar e promover a visibilidade;\nPensar e trabalhar pensando no todo;\nManter os processos simples e práticos;\nOtimizar e automatizar constantemente.\n\n\n\nAs 4 dimensões do ITIL 4\n\n\n\nRepresentação gráfica das dimensões do ITIL 4.\n\n\nAs dimensões do ITIL são necessárias para a entrega de valor ao cliente, além de facilitar a visão holística da gestão de serviços. Todas são afetadas por fatores internos e externos à organização.\nAs 4 dimensões são:\n\nOrganizações e pessoas;\nInformação e tecnologia;\nParceiros e fornecedores;\nFluxos de valor e processos.\n\n\n\nAs 34 práticas do ITIL 4\nAs práticas do ITIL 4 são “um conjunto de recursos necessários para realizar o trabalho ou cumprir um objetivo”. Elas têm como objetivo dar uma visão holística do sistema de serviços, ao considerar elementos como cultura, tecnologia, informações e gerenciamento de dados.\nA palavra “prática” também evita as ambiguidades do termo “processos”, que é usado no dia a dia das empresas em todos os departamentos. Hoje, o ITIL considera um processo como “um conjunto de atividades que transformam entradas em saídas”.\nAs práticas são divididas em 3 grandes grupos:\n\n\n1. Práticas gerais de gestão\n\nGerenciamento da estratégia\nGerenciamento da segurança da informação\nGerenciamento de fornecedor\nGerenciamento de mudança organizacional\nGerenciamento de projetos\nGerenciamento de relacionamento\nGerenciamento de riscos\nGerenciamento de talento e força de trabalho\nGerenciamento do conhecimento\nGerenciamento do portfólio\nGerenciamento financeiro dos serviços\nGestão da arquitetura\nMedição e reporte\nMelhoria contínua\n\n\n\n2. Práticas de gestão de serviço\n\nAnálise de negócio\nCentral de serviço\nDesenho de serviço\nGerenciamento de ativos de TI\nGerenciamento de capacidade e desempenho\nGerenciamento do catálogo de serviços\nGerenciamento de configuração de serviço\nGerenciamento de continuidade de serviço\nGerenciamento de disponibilidade\nGerenciamento de incidente\nGerenciamento de liberação\nGerenciamento de nível de serviço\nGerenciamento de problema\nGerenciamento de requisição de serviço\nHabilitação de mudança\nMonitoramento e gerenciamento de evento\nValidação e teste de serviço\n\n\n\n3. Práticas de gestão técnica\n\nDesenvolvimento e gerenciamento de software\nGerenciamento de implantação\nGerenciamento de infraestrutura e plataforma\n\nNenhuma prática está vinculada a um elemento do SVS nem é pré-requisito para a adoção de outras práticas. Não é obrigatório usar todas as 34 simultaneamente."
  },
  {
    "objectID": "governanca_ti.html#itil-4---prof.-gabriel-pacheco-youtube",
    "href": "governanca_ti.html#itil-4---prof.-gabriel-pacheco-youtube",
    "title": "Governança de TI",
    "section": "ITIL 4 - Prof. Gabriel Pacheco (Youtube)",
    "text": "ITIL 4 - Prof. Gabriel Pacheco (Youtube)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Resumo",
    "section": "",
    "text": "Material de estudo para concurso do BRDE, cargo Analista de Sistemas – Subárea Ciência de Dados.\nData da prova: 12/03/2023\nREQUISITO: Diploma de graduação, devidamente registrado, em pelo menos um dos seguintes cursos de nível superior: Análise de Sistemas; Tecnologia da Informação; Sistemas de Informação; Processamento de Dados; Ciência da Computação; Engenharia da Computação; Engenharia de Sistemas; Bacharelado em Informática; Administração com Ênfase em Análise de Sistemas.\nNÍVEL SUPERIOR COMPLETO CONHECIMENTOS ESPECÍFICOS CARGO C07: ANALISTA DE SISTEMAS – SUBÁREA CIÊNCIA DE DADOS PROGRAMA:\na) Banco de Dados: Fundamentos de administração de dados: Segurança; Modelagem de dados: Modelo entidade-relacionamento (entidades, atributos, chaves e relacionamentos) e Normalização;\nb) Fundamentos de Banco de Dados: Conceitos: Sistemas de gerência de banco de dados (SGBD), Arquitetura, modelos lógicos e representação física; Organização física e métodos de acesso; Conceito de transação, concorrência, recuperação, integridade; Linguagens de definição (DDL) e manipulação de dados (DML) em SGBDs relacionais; Procedimentos (stored procedures), funções (functions), visões (views), visões materializadas (materialized views) e gatilhos (triggers), Linguagem de consulta estruturada (SQL, Avaliação de modelos de dados, Técnicas de engenharia reversa para criação e atualização de modelos de dados, Integração dos dados (ETL, Transferência de Arquivos e Integração via Base de Dados, Data Lakes e Soluções para Big Data, Diferenciação entre bancos relacionais, multidimensionais, documentos e grafos.\nc) Análise de dados e informações: Dado, informação, conhecimento e inteligência; Conceitos, fundamentos, características, técnicas e métodos de Business Intelligence (BI); Mapeamento de fontes de dados, Dados estruturados e dados não estruturados, Conceitos de OLAP e suas operações, Conceitos de Data Warehouse. Técnicas de modelagem e otimização de bases de dados multidimensionais, Construção de relatórios e dashboards interativos em ferramentas de BI, Manipulação de dados em planilhas, Geração de insights a partir de relatórios e dashboards, BI como suporte a processos de tomada decisão, Conceitos Básicos em Séries Temporais, Conceitos Básicos de estatística descritiva, probabilística e testes de hipótese, Manipulação, tratamento e visualização de dados, Tratamento de dados faltantes, Tratamento de dados categóricos, Normalização numérica, Detecção e tratamento de outliers;\nd) Aprendizado de máquina (machine learning): Regressão Linear e Regressão Logística, Classificação, Métricas de avaliação, Overfitting e underfitting de modelos, Regularização; Seleção de modelos: Erro de Generalização, Validação Cruzada, Conjuntos de Treino, Validação e Teste; Conceitos de aprendizado não supervisionado, Clustering, Árvores de decisão e random forests, Máquina de suporte de vetores (SVM), Naive Bayes, K-NN;\ne) Plataforma de BI Microsoft: SQL Server, SQL Server Management Studio, SQL Server Integration Services, SQL Server Analysis Services, Power BI Report Server, Power BI Desktop, Serviço Power BI em Nuvem;\nf) Gerenciamento de Projetos: Conceitos básicos do PMBOK 7ª Edição, Metodologia SCRUM;\ng) Governança de TI: ITIL versão 4 (ITIL 4): Operação de Serviços (Gerenciamento de Eventos, Gerenciamento de Incidentes, Gerenciamento de Problemas, Cumprimento de Requisições, Gerenciamento de Acessos), Desenho de Serviços (Gerenciamento de Níveis de Serviço, Gerenciamento de Capacidade, Gerenciamento de Disponibilidade, Gerenciamento de Continuidade de Serviços de TI, Gerenciamento de Continuidade de Negócio), Transição de Serviços (Gerenciamento de Configuração e Ativos de Serviços de TI, Gerenciamento de Liberação e Implantação, Gerenciamento de Mudanças), Melhoria Contínua de Serviços, Métricas (Fatores Críticos de Sucesso - CSFs, Índices Chave de Performance - KPIs).\n."
  },
  {
    "objectID": "olap.html",
    "href": "olap.html",
    "title": "Conceitos de OLAP",
    "section": "",
    "text": "Conceitos de OLAP"
  },
  {
    "objectID": "olap.html#canaltech",
    "href": "olap.html#canaltech",
    "title": "Conceitos de OLAP",
    "section": "Canaltech",
    "text": "Canaltech\nO OLAP, do inglês “On-line Analytical Processing”, trata da capacidade de analisar grandes volumes de informações nas mais diversas perspectivas dentro de um Data Warehouse (DW). O OLAP também faz referência às ferramentas analíticas utilizadas no BI para a visualização das informações gerenciais e dá suporte para as funções de análises do negócio organizacional.\nOs sistemas OLTP e OLAP se diferenciam em diversos outros aspectos. Vejamos:\n\nEm resumo podemos dizer que a grande diferença está no fato de que um está direcionado ao funcionamento dentro do ambiente operacional (OLTP) e o outro com foco essencialmente gerencial (OLAP)."
  },
  {
    "objectID": "olap.html#brasil-escola",
    "href": "olap.html#brasil-escola",
    "title": "Conceitos de OLAP",
    "section": "Brasil Escola",
    "text": "Brasil Escola\n5.2. OLAP\nSegundo Michel (2003), OLAP (On-Line Analytical Processing ou Processamento Analítico On-Line) é um sistema de informação multidimensional cuja tecnologia de construção permite aos analistas de negócios, gerentes e executivos analisar e visualizar dados corporativos de forma rápida, consistente e principalmente interativa, ou seja, é onde são extraídos e gerados os relatórios para os usuários. Na figura 8, mostra que o OLAP fornece informações aos usuários.\nFigura 8: OLAP\n\nDa mesma forma como o BI, O OLAP não pode ser definido, como uma ferramenta ou um processo, mas sim um conjunto dos mesmos, pois os elementos essenciais para a criação de um OLAP é sua aplicabilidade em diversas camadas da tecnologia, como armazenamento e linguagem de programação, THOMSEN, 2002, complementa dizendo que \"[...]De modo geral, pode-se falar de conceitos OLAP, linguagens OLAP, camadas de produtos OLAP e produtos de OLAP completos[...]\".\nO OLAP se difere do ETL, basicamente, pelo fato de ETL fazer a extração de dados diretamente de vários bancos, visando a sua organização e as soluções OLAP, extraem informações que foram geradas pelo ETL, se referindo a um conjunto de ferramentas voltadas para o acesso e análise ad-hoc de dados.\nBILL INMON, 2002 conceitua ad-hoc como:\nConsultas com acesso casual único e tratamento dos dados segundo parâmetros nunca antes utilizados, geralmente executados de forma iterativa e heurística. Isso tudo nada mais é do que o próprio usuário gerar consultas de acordo com suas necessidades de cruzar as informações de uma forma não vista e com métodos que o levem a descoberta daquilo que procura.\"\nEm BI, o OLAP pode se apresentar principalmente de duas formas, como MOLAP, que é mais indicado para Data Marts e ROLAP que é mais indicado para Data Warehouse. Nos Data Marts o método de armazenamento de dados OLAP é chamado de MOLAP, que usa a tecnologia MDDB (MultiDimensional Database), isto se deve pelo fato de que os DM são mais específicos e a análise será mais limitada e com pouco detalhamento. Nos DW, o método é o ROLAP, que utiliza a tecnologia (Relational DataBase Management System), que possibilita um uso maior de funções e uma análise com mais confiabilidade na grande gama de informações que o DW possui.\nPara \"navegar\" nas dimensões do \"cubo\" OLAP, emprega-se o uso de operadores dimensionais, que tem papeis distintos, podendo ser para aumentar e diminuir a granulidade, que é o nível de detalhamento a ser visualizado, ou então para ordenar e classificar as informações, na seção 4.2.1 algumas operações são demonstradas.\n\n5.3. Operações\nUma das características mais importantes das ferramentas OLAP é a possibilidade de realizar algumas operações no decorrer da implementação, que nos fornece total controle das informações a serem exibidas e ordenadas. Existem variados tipos de comandos, mas comumente no BI utiliza-se algumas principais e são elas: Drill Across, Drill Up, Drill Down e Drill-Through.\nFigura 9: Operações\n\n5.3.1. Drill Across\nÉ um comando para pular de um nível intermediário dentro de uma dimensão para outra dimensão. É necessário a utilização de duas tabelas fatos e essas tabelas tem que compartilhar a mesma dimensão intermediária. Segundo Kimball (2002), \"trata-se de uma operação sobre dois cubos. Os dados nos dois cubos são combinados nas dimensões comuns aos mesmos\". Além de \"pular\" entre as dimensões, também é possível compara-las, por exemplo, é possível traçar um comparativo entre duas dimensões, como o valor total de vendas, pelo numero de um determinado produto vendido, sendo necessário elas apenas compartilharem alguma dimensão. Barbieri, 2001 completa dizendo que \"[...] embora correlacionadas, estão em estruturas separadas, porém unidas por algumas dimensões coerentes\".\n\n5.3.2. Drill Up e Drill Down\nO Drill-up é o aumento na hierarquia de uma dimensão, por exemplo, imagina uma dimensão \"Tempo\" onde estão organizadas as informações em dia, mês, semestre e ano, vamos supor que queiramos ir, do dia 10 para o mês de março, essas operações não vão de um cubo a outro, mas sim na mesma dimensão, aumentando assim a granularidade do DW e diminui o nível de detalhamento.\nJá o Drill Down é o contrário de Drill UP, é a descida na hierarquia de uma dimensão, indo de um mês para um dia diminuindo a granularidade e aumentando o nível de detalhe.\n\n\n5.3.3. Drill Through\nPossui o funcionamento parecido com o Drill Down, porém, tem como característica a possibilidade buscar os dados, ou informações, fora da estrutura principal. Por exemplo, após alcançar o nível máximo de detalhe em uma tabela fato, tem necessidade de se obter mais detalhe sobre determinada célula, como a nota fiscal, por exemplo, com o Drill Through é possível acessar o arquivo de origem dessa informação, diminuindo a granularidade, aumentando o nível de detalhe e saindo da estrutura principal do DW ou de um Data Mart."
  }
]